# -*- coding: utf-8 -*-
"""
utils.py - ê³µí†µ ìœ í‹¸ë¦¬í‹°

ì—­í• :
1. ì´ìŠˆ íƒ€ì… ì •ê·œí™” (í•œê¸€ â†’ ì˜ë¬¸)
2. ADF â†” í‰ë¬¸ ë³€í™˜
3. ì—ëŸ¬ ë©”ì‹œì§€ íŒŒì‹±
4. ë¼ë²¨ ìë™ ì œì•ˆ

ì—°ê²°:
- jira_client.py â†’ norm_issue_type, adf_paragraph ì‚¬ìš©
- milvus_client.py â†’ adf_to_textë¡œ ì„¤ëª… ì¶”ì¶œ
- graph.py â†’ suggest_labelsë¡œ ìë™ ë¼ë²¨
"""

from typing import Any, Dict, Optional, List
import requests

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì´ìŠˆ íƒ€ì… ì •ê·œí™” (ë™ì  ë§¤ì¹­)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# í•œê¸€ â†” í•œê¸€/ì˜ë¬¸ ë§¤í•‘ (ì–‘ë°©í–¥)
# Jiraì— "ë²„ê·¸", "ì—í”½", "ì›¹ ê°€ì´ë“œ" ë“± í•œê¸€ë¡œ ë“±ë¡ë˜ì–´ ìˆìŒ
TYPE_ALIASES = {
    # ë²„ê·¸ ê´€ë ¨
    "bug": "ë²„ê·¸", "ë²„ê·¸": "ë²„ê·¸", "ì˜¤ë¥˜": "ë²„ê·¸", "ì—ëŸ¬": "ë²„ê·¸",
    
    # ì—í”½ ê´€ë ¨
    "epic": "ì—í”½", "ì—í”½": "ì—í”½",
    
    # íƒœìŠ¤í¬ ê´€ë ¨
    "task": "Task", "í…ŒìŠ¤í¬": "Task", "ì‘ì—…": "Task", "íƒœìŠ¤í¬": "Task",
    
    # ìŠ¤í† ë¦¬ ê´€ë ¨
    "story": "Story", "ìŠ¤í† ë¦¬": "Story", "ì‚¬ìš©ììŠ¤í† ë¦¬": "Story",
    
    # ì„œë¸ŒíƒœìŠ¤í¬ ê´€ë ¨
    "subtask": "Subtask", "í•˜ìœ„ì‘ì—…": "Subtask", "í•˜ìœ„íƒœìŠ¤í¬": "Subtask",
    "ì„œë¸ŒíƒœìŠ¤í¬": "Subtask", "ì„œë¸Œì‘ì—…": "Subtask",
    
    # ì›¹ ê°€ì´ë“œ ê´€ë ¨
    "webguide": "ì›¹ ê°€ì´ë“œ", "ì›¹ê°€ì´ë“œ": "ì›¹ ê°€ì´ë“œ", "ì›¹": "ì›¹ ê°€ì´ë“œ", 
    "ê°€ì´ë“œ": "ì›¹ ê°€ì´ë“œ", "guide": "ì›¹ ê°€ì´ë“œ",
    
    # ì—ì´ì „íŠ¸ ê´€ë ¨
    "agent": "ì—ì´ì „íŠ¸", "ì—ì´ì „íŠ¸": "ì—ì´ì „íŠ¸", "ë´‡": "ì—ì´ì „íŠ¸", "ì±—ë´‡": "ì—ì´ì „íŠ¸",
    
    # PDF ë¶„ì„ ê´€ë ¨
    "pdf": "PDFë¶„ì„", "pdfë¶„ì„": "PDFë¶„ì„", "í”¼ë””ì—í”„": "PDFë¶„ì„",
    "í”¼ë””ì—í”„ë¶„ì„": "PDFë¶„ì„", "ë¬¸ì„œë¶„ì„": "PDFë¶„ì„",
    
    # ë¯¸íŒ… ê´€ë ¨
    "meeting": "ë¯¸íŒ…", "ë¯¸íŒ…": "ë¯¸íŒ…", "íšŒì˜": "ë¯¸íŒ…", "ë…¼ì˜": "ë¯¸íŒ…",
    
    # í”„ë¡ íŠ¸ì—”ë“œ ê´€ë ¨
    "frontend": "í”„ë¡ íŠ¸ì—”ë“œ", "í”„ë¡ íŠ¸ì—”ë“œ": "í”„ë¡ íŠ¸ì—”ë“œ", "í”„ë¡ íŠ¸": "í”„ë¡ íŠ¸ì—”ë“œ",
    "fe": "í”„ë¡ íŠ¸ì—”ë“œ", "front": "í”„ë¡ íŠ¸ì—”ë“œ",
    
    # ë°±ì—”ë“œ ê´€ë ¨
    "backend": "ë°±ì—”ë“œ", "ë°±ì—”ë“œ": "ë°±ì—”ë“œ", "ë°±": "ë°±ì—”ë“œ", 
    "be": "ë°±ì—”ë“œ", "back": "ë°±ì—”ë“œ",
}


def fuzzy_match_issue_type(user_input: str, available_types: List[str]) -> Optional[str]:
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ì‹¤ì œ Jira ì´ìŠˆ íƒ€ì…ê³¼ í¼ì§€ ë§¤ì¹­
    
    ë§¤ì¹­ ì „ëµ:
    1. ë³„ì¹­ í…Œì´ë¸” ì¡°íšŒ
    2. ì •í™• ë§¤ì¹˜
    3. ì •ê·œí™” ë§¤ì¹˜
    4. ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹˜
    5. í¸ì§‘ ê±°ë¦¬ (Levenshtein) ë§¤ì¹­
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥
        available_types: Jira ì‹¤ì œ íƒ€ì… ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ê°€ì¥ ìœ ì‚¬í•œ íƒ€ì… ë˜ëŠ” None
    """
    if not user_input or not available_types:
        return None
    
    inp_original = user_input.strip()
    inp = inp_original.lower().replace(" ", "").replace("-", "").replace("_", "")
    
    # 1. ë³„ì¹­ í…Œì´ë¸” ì¡°íšŒ
    standard_name = TYPE_ALIASES.get(inp)
    if standard_name and standard_name in available_types:
        return standard_name
    
    # 2. ì •í™• ë§¤ì¹˜ (ì›ë³¸ ê·¸ëŒ€ë¡œ)
    if inp_original in available_types:
        return inp_original
    
    # 3. ì •ê·œí™” ë§¤ì¹˜
    for atype in available_types:
        atype_norm = atype.lower().replace(" ", "").replace("-", "").replace("_", "")
        if inp == atype_norm:
            return atype
    
    # 4. ë¶€ë¶„ ë§¤ì¹˜ (í¬í•¨ ì—¬ë¶€)
    best_match = None
    best_score = 0
    
    for atype in available_types:
        atype_norm = atype.lower().replace(" ", "").replace("-", "").replace("_", "")
        
        # í¬í•¨ ê´€ê³„
        if inp in atype_norm or atype_norm in inp:
            score = min(len(inp), len(atype_norm)) / max(len(inp), len(atype_norm))
            if score > best_score:
                best_score = score
                best_match = atype
    
    if best_score > 0.5:
        return best_match
    
    # 5. í¸ì§‘ ê±°ë¦¬ (Levenshtein Distance)
    def levenshtein_distance(s1: str, s2: str) -> int:
        """ë¬¸ìì—´ ê°„ í¸ì§‘ ê±°ë¦¬ ê³„ì‚°"""
        if len(s1) < len(s2):
            return levenshtein_distance(s2, s1)
        if len(s2) == 0:
            return len(s1)
        
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    # í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜ ë§¤ì¹­
    for atype in available_types:
        atype_norm = atype.lower().replace(" ", "").replace("-", "").replace("_", "")
        
        distance = levenshtein_distance(inp, atype_norm)
        max_len = max(len(inp), len(atype_norm))
        
        # ìœ ì‚¬ë„ = 1 - (ê±°ë¦¬ / ìµœëŒ€ê¸¸ì´)
        similarity = 1 - (distance / max_len) if max_len > 0 else 0
        
        if similarity > best_score and similarity > 0.6:  # 60% ì´ìƒ ìœ ì‚¬
            best_score = similarity
            best_match = atype
    
    return best_match if best_score > 0.6 else None


def llm_match_issue_type(user_input: str, available_types: List[str]) -> Optional[str]:
    """
    LLMìœ¼ë¡œ ì´ìŠˆ íƒ€ì… ë§¤ì¹­ (í¼ì§€ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
    
    ë¹„ìš© ìµœì í™”:
    - í¸ì§‘ ê±°ë¦¬ ì‹¤íŒ¨ ì‹œì—ë§Œ í˜¸ì¶œ
    - ì§§ì€ í”„ë¡¬í”„íŠ¸ + ë‚®ì€ max_tokens
    - temperature=0 (ê²°ì •ë¡ ì )
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥
        available_types: Jira ì‹¤ì œ íƒ€ì… ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ë§¤ì¹­ëœ íƒ€ì… ë˜ëŠ” None
    
    ì˜ˆì‹œ:
        available = ["ë²„ê·¸", "Code Review", "ë””ìì¸ ë¦¬ë·°"]
        llm_match_issue_type("ì½”ë“œë¦¬ë·°", available) â†’ "Code Review"
    """
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ë™ì  import (ì„ íƒì  ê¸°ëŠ¥)
    try:
        from openai import OpenAI
        from .config import OPENAI_API_KEY, CHAT_MODEL
        
        if not OPENAI_API_KEY:
            return None
        
        client = OpenAI(api_key=OPENAI_API_KEY)
    except Exception:
        return None
    
    # í”„ë¡¬í”„íŠ¸ (ê°„ê²°í•˜ê²Œ)
    types_str = ", ".join([f'"{t}"' for t in available_types])
    prompt = f"""ì‚¬ìš©ì ì…ë ¥: "{user_input}"
ê°€ëŠ¥í•œ íƒ€ì…: {types_str}

ê°€ì¥ ì í•©í•œ íƒ€ì… í•˜ë‚˜ë§Œ ë°˜í™˜. ì—†ìœ¼ë©´ "NONE".
íƒ€ì…ëª…ë§Œ ë°˜í™˜, ì„¤ëª… ê¸ˆì§€."""
    
    try:
        resp = client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            max_tokens=30
        )
        
        result = resp.choices[0].message.content.strip().strip('"')
        
        # ìœ íš¨ì„± ê²€ì¦
        if result == "NONE" or result not in available_types:
            return None
        
        return result
    
    except Exception as e:
        print(f"[LLM ë§¤ì¹­ ì‹¤íŒ¨] {e}")
        return None


def norm_issue_type(s: Optional[str], 
                    available_types: Optional[List[str]] = None,
                    use_llm: bool = False) -> Optional[str]:
    """
    ì´ìŠˆ íƒ€ì… ì •ê·œí™” (ë‹¤ë‹¨ê³„ ë§¤ì¹­)
    
    ë§¤ì¹­ ì „ëµ (ìˆœì„œëŒ€ë¡œ):
    1. ë³„ì¹­ í…Œì´ë¸” ì¡°íšŒ (ì¦‰ì‹œ)
    2. í¼ì§€ ë§¤ì¹­ (í¸ì§‘ ê±°ë¦¬ í¬í•¨)
    3. LLM ë³´ì¡° (ì„ íƒì , use_llm=True ì‹œ)
    4. í´ë°± (ì›ë³¸ ë°˜í™˜)
    
    Args:
        s: ì‚¬ìš©ì ì…ë ¥
        available_types: Jira ì‹¤ì œ íƒ€ì… ë¦¬ìŠ¤íŠ¸ (ê¶Œì¥)
        use_llm: Trueë©´ í¼ì§€ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ LLM ì‚¬ìš© (ë¹„ìš© ë°œìƒ)
    
    Returns:
        ì •ê·œí™”ëœ íƒ€ì… ë˜ëŠ” None
    
    ì˜ˆì‹œ:
        types = ["ë²„ê·¸", "ì—í”½", "ì›¹ ê°€ì´ë“œ", "Code Review"]
        
        # ë³„ì¹­ í…Œì´ë¸” (ë¬´ë£Œ)
        norm_issue_type("bug", types) â†’ "ë²„ê·¸"
        
        # í¸ì§‘ ê±°ë¦¬ (ë¬´ë£Œ)
        norm_issue_type("ì›¹ê°€ì´ë“œ", types) â†’ "ì›¹ ê°€ì´ë“œ"
        
        # LLM ë³´ì¡° (ë¹„ìš© ë°œìƒ)
        norm_issue_type("ì½”ë“œë¦¬ë·°", types, use_llm=True) â†’ "Code Review"
    """
    if s is None:
        return None
    
    # 1. íƒ€ì… ë¦¬ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í¼ì§€ ë§¤ì¹­ (ê¶Œì¥)
    if available_types:
        match = fuzzy_match_issue_type(s, available_types)
        if match:
            return match
        
        # 2. LLM ë³´ì¡° (ì„ íƒì )
        if use_llm:
            llm_match = llm_match_issue_type(s, available_types)
            if llm_match:
                return llm_match
    
    # 3. í´ë°±: ë³„ì¹­ í…Œì´ë¸” ì§ì ‘ ì¡°íšŒ
    inp = s.strip().lower().replace(" ", "").replace("-", "").replace("_", "")
    standard = TYPE_ALIASES.get(inp)
    
    if standard:
        return standard
    
    # 4. ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return s.strip() if s.strip() else None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—ëŸ¬ ë©”ì‹œì§€ íŒŒì‹±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_err(r: requests.Response) -> str:
    """
    Jira API ì—ëŸ¬ë¥¼ ì½ê¸° ì‰½ê²Œ ë³€í™˜
    
    Args:
        r: requests.Response ê°ì²´
    
    Returns:
        ì •ë¦¬ëœ ì—ëŸ¬ ë©”ì‹œì§€
    
    ì˜ˆì‹œ:
        parse_err(response)
        â†’ "project: Project is required | summary: Field is required"
    """
    try:
        j = r.json()
    except Exception:
        return f"{r.status_code} {r.text[:300]}"
    
    msgs = []
    
    # errorMessages ë°°ì—´
    for m in (j.get("errorMessages") or []):
        msgs.append(m)
    
    # errors ë”•ì…”ë„ˆë¦¬
    for k, v in (j.get("errors") or {}).items():
        msgs.append(f"{k}: {v}")
    
    return " | ".join(msgs) if msgs else f"{r.status_code} {r.text[:300]}"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ADF (Atlassian Document Format) ë³€í™˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def adf_paragraph(text: Optional[str]) -> Dict[str, Any]:
    """
    í‰ë¬¸ â†’ ADF ë³€í™˜ (Jira description í•„ë“œìš©)
    
    Args:
        text: í‰ë¬¸ ë¬¸ìì—´
    
    Returns:
        ADF JSON ê°ì²´
    
    ì˜ˆì‹œ:
        adf_paragraph("ë²„ê·¸ ìˆ˜ì • í•„ìš”")
        â†’ {"type": "doc", "version": 1, "content": [...]}
    """
    if not text:
        return {
            "type": "doc",
            "version": 1,
            "content": []
        }
    
    return {
        "type": "doc",
        "version": 1,
        "content": [
            {
                "type": "paragraph",
                "content": [
                    {
                        "type": "text",
                        "text": text
                    }
                ]
            }
        ]
    }


def adf_to_text(adf: Any, max_len: int = 5000) -> str:
    """
    ADF â†’ í‰ë¬¸ ë³€í™˜ (ì„ë² ë”©/ê²€ìƒ‰ìš©)
    
    Args:
        adf: ADF dict ë˜ëŠ” ë¬¸ìì—´
        max_len: ìµœëŒ€ ê¸¸ì´
    
    Returns:
        í‰ë¬¸ ë¬¸ìì—´
    
    ì˜ˆì‹œ:
        adf = {"type": "doc", "content": [...]}
        adf_to_text(adf)
        â†’ "ë²„ê·¸ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\n\nì¬í˜„ ë‹¨ê³„: ..."
    """
    if not adf:
        return ""
    
    # ì´ë¯¸ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ
    if isinstance(adf, str):
        return adf[:max_len] if len(adf) > max_len else adf
    
    # ADFê°€ ì•„ë‹ˆë©´ ë¹ˆ ë¬¸ìì—´
    if not isinstance(adf, dict) or adf.get("type") != "doc":
        return ""
    
    out = []
    
    def walk(node: Any):
        """ì¬ê·€ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        if isinstance(node, dict):
            node_type = node.get("type")
            
            # í…ìŠ¤íŠ¸ ë…¸ë“œ
            if node_type == "text" and "text" in node:
                out.append(node["text"])
            
            # ìì‹ ë…¸ë“œ íƒìƒ‰
            if "content" in node and isinstance(node["content"], list):
                for child in node["content"]:
                    walk(child)
            
            # ë¬¸ë‹¨ ë’¤ ê°œí–‰
            if node_type in ("paragraph", "heading", "bulletList", "orderedList"):
                out.append("\n")
        
        elif isinstance(node, list):
            for item in node:
                walk(item)
    
    walk(adf)
    
    text = "".join(out).strip()
    
    # ìµœëŒ€ ê¸¸ì´ ì œí•œ
    if len(text) > max_len:
        text = text[:max_len] + " ..."
    
    return text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¼ë²¨ ìë™ ì œì•ˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASIC_KEYWORDS = {
    "bug": ["bug", "ì—ëŸ¬", "ì˜¤ë¥˜", "ì˜ˆì™¸", "exception", "error", "fix", "hotfix"],
    "api": ["api", "endpoint", "rest", "graphql", "ìš”ì²­", "ì‘ë‹µ", "request", "response"],
    "ui": ["ui", "ux", "í™”ë©´", "ë²„íŠ¼", "ì»´í¬ë„ŒíŠ¸", "component", "layout", "design"],
    "backend": ["ì„œë²„", "server", "db", "database", "ì¿¼ë¦¬", "query", "service", "repository", "ë°±ì—”ë“œ"],
    "frontend": ["í”„ë¡ íŠ¸", "í”„ë¡ íŠ¸ì—”ë“œ", "react", "vue", "angular", "í´ë¼ì´ì–¸íŠ¸", "client"],
    "urgent": ["ê¸´ê¸‰", "ê¸‰í•¨", "hotfix", "critical", "ğŸ”¥", "asap"],
    "test": ["í…ŒìŠ¤íŠ¸", "test", "unit", "integration", "e2e"],
    "docs": ["ë¬¸ì„œ", "documentation", "readme", "ê°€ì´ë“œ", "guide", "ì›¹ê°€ì´ë“œ"],
    "meeting": ["ë¯¸íŒ…", "íšŒì˜", "meeting", "ë…¼ì˜", "discussion"],
    "ai": ["ì—ì´ì „íŠ¸", "agent", "llm", "gpt", "ai", "ì¸ê³µì§€ëŠ¥"],
    "pdf": ["pdf", "í”¼ë””ì—í”„", "ë¬¸ì„œë¶„ì„", "íŒŒì¼"],
}


def suggest_labels(summary: str, description: str = "") -> List[str]:
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ ë¼ë²¨ ìë™ ì œì•ˆ
    
    Args:
        summary: ì´ìŠˆ ì œëª©
        description: ì´ìŠˆ ì„¤ëª…
    
    Returns:
        ì œì•ˆëœ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (ì •ë ¬ë¨)
    
    ì˜ˆì‹œ:
        suggest_labels("ë¡œê·¸ì¸ API ë²„ê·¸ ìˆ˜ì •", "ì„œë²„ ì‘ë‹µ ì—ëŸ¬")
        â†’ ["api", "backend", "bug"]
    """
    labs = set()
    
    # ì œëª© + ì„¤ëª…
    text = (summary or "") + " " + (description or "")
    text_lower = text.lower()
    
    # í‚¤ì›Œë“œ ë§¤ì¹­
    for label, keywords in BASIC_KEYWORDS.items():
        if any(kw in text_lower for kw in keywords):
            labs.add(label)
    
    return sorted(list(labs))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def summarize_search_results(results: List[Dict[str, Any]]) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•œ ì¤„ ìš”ì•½
    
    Args:
        results: ì´ìŠˆ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ìš”ì•½ ë¬¸ìì—´
    
    ì˜ˆì‹œ:
        summarize_search_results([...])
        â†’ "ìœ í˜• ë¶„í¬(Task:3, Bug:2), ëŒ€í‘œ ì œëª©: ë¡œê·¸ì¸ ìˆ˜ì •, API ê°œì„ "
    """
    if not results:
        return "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
    
    from collections import Counter
    
    # ì´ìŠˆ íƒ€ì… ì¹´ìš´íŠ¸
    types = Counter([r.get("issuetype") for r in results if r.get("issuetype")])
    top3_types = ", ".join([f"{k}:{v}" for k, v in types.most_common(3)])
    
    # ëŒ€í‘œ ì œëª©
    titles = ", ".join([
        r.get("summary", "")[:30] 
        for r in results[:3]
    ])
    
    return f"ìœ í˜• ë¶„í¬({top3_types}), ëŒ€í‘œ ì œëª©: {titles}"