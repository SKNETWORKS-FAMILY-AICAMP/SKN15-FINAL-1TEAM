"""LangGraph based CLI orchestrating Jira CRUD bot with OpenAI + FAISS ranking."""
from __future__ import annotations

import os
import sys
import textwrap
from pathlib import Path
from dataclasses import dataclass
from typing import Any, Dict, Iterable, List, Literal, Optional, Sequence, Tuple, TypedDict

import faiss  # type: ignore
import numpy as np
from dotenv import load_dotenv
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langgraph.graph import END, StateGraph
from pydantic import BaseModel, Field

from jira_client import Issue, JiraClient, JiraClientError, normalize_issue_type

Intent = Literal["create", "update", "delete", "search", "explain", "chit_chat", "unknown"]


class BotState(TypedDict, total=False):
    messages: List[BaseMessage]
    user_input: str
    intent: Intent
    slots: Dict[str, Any]
    nlu_raw: Dict[str, Any]
    response: str
    pending: Dict[str, Any]


class NLUResult(BaseModel):
    intent: Intent = Field(description="Detected user intent for Jira workflow")
    project: Optional[str] = Field(default=None, description="Jira project key")
    issue_type: Optional[str] = Field(default=None, description="Issue type name")
    summary: Optional[str] = None
    description: Optional[str] = None
    issue_key: Optional[str] = Field(default=None, description="Existing issue key")
    due_date: Optional[str] = Field(default=None, description="Due date in YYYY-MM-DD")
    priority: Optional[str] = None
    keyword: Optional[str] = Field(default=None, description="Search keyword")
    keywords: Optional[List[str]] = Field(default=None, description="Search keywords")
    use_adf: Optional[bool] = Field(default=None, description="Whether to send description as ADF")

    class Config:
        extra = "allow"


@dataclass
class Services:
    jira: JiraClient
    chat_llm: ChatOpenAI
    explain_llm: ChatOpenAI
    chit_chat_llm: ChatOpenAI
    nlu_llm: Any
    embeddings: OpenAIEmbeddings


@dataclass
class ValidationResult:
    can_proceed: bool
    message: Optional[str] = None
    available_types: List[str] | None = None
    project_id: Optional[str] = None


NLU_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ Jira CLI ë´‡ì˜ NLU ëª¨ë“ˆìž…ë‹ˆë‹¤. ì‚¬ìš©ìžì˜ ë°œí™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ intentì™€ ìŠ¬ë¡¯ì„ JSON êµ¬ì¡°ë¡œ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤.
ê°€ëŠ¥í•œ intentëŠ” create, update, delete, search, explain, chit_chat, unknown ìž…ë‹ˆë‹¤.
- ì´ìŠˆ í‚¤ëŠ” ëŒ€ë¬¸ìž í”„ë¡œì íŠ¸í‚¤-ë²ˆí˜¸ í˜•íƒœ(HINTON-123)
- í”„ë¡œì íŠ¸ í‚¤, ì´ìŠˆ ìœ í˜•, ìš”ì•½, ì„¤ëª…, ë§ˆê°ì¼(YYYY-MM-DD), ìš°ì„ ìˆœìœ„, í‚¤ì›Œë“œ ë“±ì„ ì¶”ì¶œí•˜ì„¸ìš”.
- ì‚¬ìš©ìžê°€ ë‹¨ìˆœ ì¸ì‚¬ë‚˜ ìž¡ë‹´ì´ë©´ intentë¥¼ chit_chat ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
- í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ intentë¥¼ unknown ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”."""

ASSISTANT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ Jira CRUD ìž‘ì—…ì„ ë•ëŠ” í•œêµ­ì–´ ì±—ë´‡ìž…ë‹ˆë‹¤. ë‹µë³€ì€ ê°„ê²°í•˜ì§€ë§Œ ì¹œì ˆí•˜ê²Œ ìž‘ì„±í•˜ì„¸ìš”."""

EXPLAIN_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ Jira ì´ìŠˆë¥¼ ì„¤ëª…í•´ì£¼ëŠ” ë„ìš°ë¯¸ìž…ë‹ˆë‹¤. ì œê³µëœ ì´ìŠˆ ì •ë³´ì™€ ì‚¬ìš©ìž ì§ˆì˜ë¥¼ ì°¸ê³ í•˜ì—¬:
1) ì™œ í•´ë‹¹ ì´ìŠˆê°€ ê´€ë ¨ì„±ì´ ë†’ì€ì§€
2) í˜„ìž¬ ìƒíƒœì™€ í•µì‹¬ ìš”ì•½
3) ì¶”ì²œ ë‹¤ìŒ ì•¡ì…˜
ì„ ìˆœì„œëŒ€ë¡œ bullet ì—†ì´ ì§§ì€ ë¬¸ë‹¨ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”."""


def load_services() -> Services:
    script_dir = Path(__file__).resolve().parent
    load_dotenv(script_dir / ".env")

    base_url = os.getenv("JIRA_BASE_URL")
    email = os.getenv("JIRA_EMAIL")
    token = os.getenv("JIRA_API_TOKEN")
    chat_model_name = os.getenv("OPENAI_CHAT_MODEL", "gpt-4o-mini")
    embed_model_name = os.getenv("OPENAI_EMBED_MODEL", "text-embedding-3-small")

    missing = [name for name, value in [
        ("JIRA_BASE_URL", base_url),
        ("JIRA_EMAIL", email),
        ("JIRA_API_TOKEN", token),
        ("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY")),
    ] if not value]
    if missing:
        missing_vars = ", ".join(missing)
        print(f"í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {missing_vars}", file=sys.stderr)
        sys.exit(1)

    jira = JiraClient(base_url, email, token)
    chat_llm = ChatOpenAI(model=chat_model_name, temperature=0.2)
    explain_llm = ChatOpenAI(model=chat_model_name, temperature=0.3)
    chit_chat_llm = ChatOpenAI(model=chat_model_name, temperature=0.6)
    nlu_llm = chat_llm.with_structured_output(NLUResult, method="function_calling")
    embeddings = OpenAIEmbeddings(model=embed_model_name)

    return Services(
        jira=jira,
        chat_llm=chat_llm,
        explain_llm=explain_llm,
        chit_chat_llm=chit_chat_llm,
        nlu_llm=nlu_llm,
        embeddings=embeddings,
    )


def build_app(services: Services):
    graph = StateGraph(BotState)

    def node_nlu(state: BotState) -> Dict[str, Any]:
        messages = list(state.get("messages", []))
        nlu_messages: List[BaseMessage] = [SystemMessage(content=NLU_SYSTEM_PROMPT)] + messages
        result = services.nlu_llm.invoke(nlu_messages)
        slots = result.model_dump(exclude_none=True)
        intent = slots.pop("intent", "unknown")

        if "keywords" in slots and slots.get("keywords") and not slots.get("keyword"):
            slots["keyword"] = " ".join(slots["keywords"])

        pending = state.get("pending", {}) or {}
        if pending.get("awaiting_issue_key"):
            # Force router to stay on pending intent until issue key arrives
            intent = pending.get("intent", intent)
            merged_slots = dict(pending.get("slots", {}))
            merged_slots.update(slots)
            slots = merged_slots
        else:
            slots = {**(pending.get("slots", {})), **slots} if pending.get("intent") == intent else slots

        slots = _normalize_slots(slots)
        return {"intent": intent, "slots": slots, "nlu_raw": result.model_dump()}

    def router(state: BotState) -> str:
        intent = state.get("intent", "unknown")
        if intent in {"create", "update", "delete", "search", "explain", "chit_chat"}:
            return intent
        return "chit_chat"

    def node_create(state: BotState) -> Dict[str, Any]:
        slots = _normalize_slots(state.get("slots", {}))
        project = slots.get("project")
        issue_type = slots.get("issue_type")
        summary = slots.get("summary")
        description = slots.get("description")
        use_adf = bool(slots.get("use_adf"))

        missing: List[str] = []
        if not project:
            missing.append("í”„ë¡œì íŠ¸")
        if not issue_type:
            missing.append("ì´ìŠˆ ìœ í˜•")
        if not summary:
            missing.append("ìš”ì•½")
        if missing:
            text = "ìƒì„±ì„ ìœ„í•´ " + ", ".join(missing) + " ê°’ì„ ì•Œë ¤ì£¼ì„¸ìš”."
            return _reply(state, text, pending={"intent": "create", "slots": slots})

        normalized_project = project.strip().upper()
        normalized_issue_type = normalize_issue_type(issue_type)
        slots["project"] = normalized_project
        slots["issue_type"] = normalized_issue_type

        validation = _validate_project_and_issue_type(
            services,
            normalized_project,
            normalized_issue_type,
        )
        if not validation.can_proceed:
            text = validation.message or "í”„ë¡œì íŠ¸/ì´ìŠˆ ìœ í˜•ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            available_types = validation.available_types or []
            if available_types:
                text += "\nì‚¬ìš© ê°€ëŠ¥í•œ ì´ìŠˆ ìœ í˜•: " + ", ".join(sorted(available_types))
            return _reply(state, text, pending={"intent": "create", "slots": slots})
        warning_text = validation.message

        try:
            issue = services.jira.create_issue(
                project_key=normalized_project,
                project_id=validation.project_id,
                issue_type=normalized_issue_type,
                summary=summary,
                description=description,
                use_adf=use_adf,
            )
        except JiraClientError as exc:
            text = f"âŒ ì´ìŠˆ ìƒì„± ì‹¤íŒ¨: {exc}"
            return _reply(state, text, pending={"intent": "create", "slots": slots})

        lines: List[str] = []
        if warning_text:
            lines.append(f"âš ï¸ {warning_text}")
        lines.extend(
            [
                "âœ… ì´ìŠˆê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:",
                f"- í‚¤: {issue.key}",
                f"- í”„ë¡œì íŠ¸: {issue.project}",
                f"- ìœ í˜•: {issue.issue_type}",
                f"- ìš”ì•½: {issue.summary}",
            ]
        )
        return _reply(state, "\n".join(lines), pending={})

    def node_update(state: BotState) -> Dict[str, Any]:
        slots = _normalize_slots(dict(state.get("slots", {})))
        pending = state.get("pending", {}) or {}
        issue_key = slots.get("issue_key")

        fields_to_update = {
            key: slots.get(key)
            for key in ("summary", "description", "due_date", "priority")
            if slots.get(key) is not None
        }
        use_adf = bool(slots.get("use_adf"))

        if not issue_key:
            project = slots.get("project")
            keyword = _keyword_from_slots(slots)
            if not project:
                return _reply(
                    state,
                    "ìˆ˜ì • í›„ë³´ë¥¼ ì°¾ìœ¼ë ¤ë©´ í”„ë¡œì íŠ¸ ì±„ë„ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤ (ì˜ˆ: í”„ë¡œì íŠ¸=HINTON).",
                    pending={"intent": "update", "slots": slots},
                )
            try:
                candidates = _collect_candidates(services, project, keyword, limit=60)
            except JiraClientError as exc:
                return _reply(
                    state,
                    f"âŒ ì´ìŠˆ ì¡°íšŒ ì‹¤íŒ¨: {exc}",
                    pending={"intent": "update", "slots": slots},
                )
            ranked = _faiss_topk(services, state.get("user_input", keyword or ""), candidates, k=5)
            if not ranked:
                return _reply(
                    state,
                    "ì¡°ê±´ì— ë§žëŠ” ì´ìŠˆë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                    pending={},
                )
            text = _format_issue_list("[ìˆ˜ì • í›„ë³´ Top-5]", ranked)
            new_pending = {
                "intent": "update",
                "slots": slots,
                "candidate_keys": [issue.key for issue in ranked],
                "awaiting_issue_key": True,
            }
            return _reply(state, text + "\ní‚¤=HINTON-123 í˜•íƒœë¡œ ìˆ˜ì •í•  ì´ìŠˆë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.", pending=new_pending)

        if not fields_to_update:
            reminder = "ìˆ˜ì •í•  í•„ë“œë¥¼ ì•Œë ¤ì£¼ì„¸ìš” (ìš”ì•½/ì„¤ëª…/ë§ˆê°/ìš°ì„ ìˆœìœ„ ë“±)."
            return _reply(
                state,
                reminder,
                pending={"intent": "update", "slots": slots, "awaiting_issue_key": False},
            )

        try:
            updated = services.jira.update_issue(
                issue_key,
                summary=fields_to_update.get("summary"),
                description=fields_to_update.get("description"),
                due_date=fields_to_update.get("due_date"),
                priority=fields_to_update.get("priority"),
                use_adf=use_adf,
            )
        except JiraClientError as exc:
            return _reply(
                state,
                f"âŒ ì´ìŠˆ ìˆ˜ì • ì‹¤íŒ¨: {exc}",
                pending={"intent": "update", "slots": slots},
            )

        text = "âœ… ì´ìŠˆê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤:\n" + _format_issue_summary(updated)
        return _reply(state, text, pending={})

    def node_delete(state: BotState) -> Dict[str, Any]:
        slots = _normalize_slots(dict(state.get("slots", {})))
        issue_key = slots.get("issue_key")

        if not issue_key:
            project = slots.get("project")
            keyword = _keyword_from_slots(slots)
            if not project:
                return _reply(
                    state,
                    "ì‚­ì œ í›„ë³´ë¥¼ ì°¾ìœ¼ë ¤ë©´ í”„ë¡œì íŠ¸ ì±„ë„ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                    pending={"intent": "delete", "slots": slots},
                )
            try:
                candidates = _collect_candidates(services, project, keyword, limit=60)
            except JiraClientError as exc:
                return _reply(
                    state,
                    f"âŒ ì´ìŠˆ ì¡°íšŒ ì‹¤íŒ¨: {exc}",
                    pending={"intent": "delete", "slots": slots},
                )
            ranked = _faiss_topk(services, state.get("user_input", keyword or ""), candidates, k=5)
            if not ranked:
                return _reply(
                    state,
                    "ì¡°ê±´ì— ë§žëŠ” ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.",
                    pending={},
                )
            text = _format_issue_list("[ì‚­ì œ í›„ë³´ Top-5]", ranked)
            pending = {
                "intent": "delete",
                "slots": slots,
                "candidate_keys": [issue.key for issue in ranked],
                "awaiting_issue_key": True,
            }
            return _reply(state, text + "\ní‚¤=HINTON-123 í˜•íƒœë¡œ ì‚­ì œí•  ì´ìŠˆë¥¼ í™•ì •í•´ì£¼ì„¸ìš”.", pending=pending)

        try:
            services.jira.delete_issue(issue_key)
        except JiraClientError as exc:
            return _reply(
                state,
                f"âŒ ì´ìŠˆ ì‚­ì œ ì‹¤íŒ¨: {exc}",
                pending={"intent": "delete", "slots": slots},
            )

        return _reply(state, f"ðŸ—‘ï¸ {issue_key} ì´ìŠˆë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.", pending={})

    def node_search(state: BotState) -> Dict[str, Any]:
        slots = _normalize_slots(state.get("slots", {}))
        project = slots.get("project")
        keyword = _keyword_from_slots(slots)
        if not project:
            return _reply(
                state,
                "ê²€ìƒ‰í•˜ë ¤ë©´ í”„ë¡œì íŠ¸ ì±„ë„ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                pending={"intent": "search", "slots": slots},
            )
        try:
            candidates = _collect_candidates(services, project, keyword, limit=60)
        except JiraClientError as exc:
            return _reply(
                state,
                f"âŒ ì´ìŠˆ ê²€ìƒ‰ ì‹¤íŒ¨: {exc}",
                pending={"intent": "search", "slots": slots},
            )
        ranked = _faiss_topk(services, state.get("user_input", keyword or ""), candidates, k=5)
        if not ranked:
            return _reply(state, "ì¡°ê±´ì— ë§žëŠ” ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.", pending={})
        text = _format_issue_list("[ê²€ìƒ‰ Top-5]", ranked)
        return _reply(state, text, pending={})

    def node_explain(state: BotState) -> Dict[str, Any]:
        slots = _normalize_slots(state.get("slots", {}))
        project = slots.get("project")
        keyword = _keyword_from_slots(slots)
        try:
            candidates = _collect_candidates(services, project, keyword, limit=60)
        except JiraClientError as exc:
            return _reply(
                state,
                f"âŒ ì´ìŠˆ ê²€ìƒ‰ ì‹¤íŒ¨: {exc}",
                pending={},
            )
        ranked = _faiss_topk(services, state.get("user_input", keyword or ""), candidates, k=1)
        if not ranked:
            return _reply(state, "ê´€ë ¨ ì´ìŠˆë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", pending={})
        target = ranked[0]
        try:
            detailed = services.jira.get_issue(target.key)
        except JiraClientError:
            detailed = target

        explain_prompt = _build_explain_prompt(detailed, state.get("user_input", ""))
        messages = [SystemMessage(content=EXPLAIN_SYSTEM_PROMPT), HumanMessage(content=explain_prompt)]
        answer = services.explain_llm.invoke(messages)
        text = "[ê°€ìž¥ ê´€ë ¨ ë†’ì€ ì´ìŠˆ]\n" + _format_issue_summary(detailed) + "\n\n" + answer.content.strip()
        return _reply(state, text, pending={})

    def node_chit_chat(state: BotState) -> Dict[str, Any]:
        messages = list(state.get("messages", []))
        convo = [SystemMessage(content=ASSISTANT_SYSTEM_PROMPT)] + messages
        response = services.chit_chat_llm.invoke(convo)
        return _reply(state, response.content.strip(), pending={})

    graph.add_node("nlu", node_nlu)
    graph.add_node("create", node_create)
    graph.add_node("update", node_update)
    graph.add_node("delete", node_delete)
    graph.add_node("search", node_search)
    graph.add_node("explain", node_explain)
    graph.add_node("chit_chat", node_chit_chat)

    graph.set_entry_point("nlu")
    graph.add_conditional_edges(
        "nlu",
        router,
        {
            "create": "create",
            "update": "update",
            "delete": "delete",
            "search": "search",
            "explain": "explain",
            "chit_chat": "chit_chat",
        },
    )
    graph.add_edge("create", END)
    graph.add_edge("update", END)
    graph.add_edge("delete", END)
    graph.add_edge("search", END)
    graph.add_edge("explain", END)
    graph.add_edge("chit_chat", END)

    return graph.compile()


def _collect_candidates(services: Services, project: Optional[str], keyword: Optional[str], *, limit: int = 60) -> List[Issue]:
    return services.jira.search_issues(project_key=project, keyword=keyword, limit=limit)


def _keyword_from_slots(slots: Dict[str, Any]) -> Optional[str]:
    keyword = slots.get("keyword")
    if not keyword and slots.get("keywords"):
        keyword = " ".join(slots["keywords"])
    if isinstance(keyword, str):
        return keyword
    return None


def _validate_project_and_issue_type(
    services: Services,
    project_key: str,
    issue_type: str,
) -> ValidationResult:
    try:
        meta = services.jira.get_create_meta(project_key)
    except JiraClientError as exc:
        return ValidationResult(
            can_proceed=True,
            message=f"í”„ë¡œì íŠ¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {exc}",
            available_types=[],
            project_id=None,
        )

    projects = meta.get("projects") if isinstance(meta, dict) else None
    if not projects:
        return ValidationResult(
            can_proceed=True,
            message=(
                "í”„ë¡œì íŠ¸ ì±„ë„ ì´ë¦„ì„ í™•ì¸í•  ìˆ˜ ì—†ì–´ Jira ì‘ë‹µ ê¸°ì¤€ìœ¼ë¡œ ê³„ì† ì‹œë„í•©ë‹ˆë‹¤. "
                "í•„ìš”í•˜ë©´ í”„ë¡œì íŠ¸ ì±„ë„ ì´ë¦„ ë˜ëŠ” ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            ),
            available_types=[],
            project_id=None,
        )

    project_meta = None
    for item in projects:
        if isinstance(item, dict) and item.get("key") == project_key:
            project_meta = item
            break
    if not project_meta:
        return ValidationResult(
            can_proceed=True,
            message=(
                "í”„ë¡œì íŠ¸ ì±„ë„ ì´ë¦„ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ì–´ Jira ì‘ë‹µ ê¸°ì¤€ìœ¼ë¡œ ê³„ì† ì‹œë„í•©ë‹ˆë‹¤. "
                "í•„ìš”í•˜ë©´ í”„ë¡œì íŠ¸ ì±„ë„ ì´ë¦„ ë˜ëŠ” ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            ),
            available_types=[],
            project_id=None,
        )

    issuetypes = project_meta.get("issuetypes")
    available_types = [it.get("name") for it in issuetypes or [] if isinstance(it, dict) and it.get("name")]

    if available_types and issue_type not in available_types:
        return ValidationResult(
            can_proceed=False,
            message=f'"{issue_type}" ìœ í˜•ì€ í”„ë¡œì íŠ¸ {project_key}ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
            available_types=available_types,
            project_id=project_meta.get("id") if isinstance(project_meta, dict) else None,
        )

    return ValidationResult(
        can_proceed=True,
        message=None,
        available_types=available_types,
        project_id=project_meta.get("id") if isinstance(project_meta, dict) else None,
    )


def _normalize_slots(slots: Dict[str, Any]) -> Dict[str, Any]:
    if not isinstance(slots, dict):
        return {}
    normalized = dict(slots)
    alias_map = {
        "project": ["project_key", "projectKey"],
        "issue_type": ["type", "issueType"],
        "issue_key": ["key", "issueKey"],
        "due_date": ["due", "dueDate"],
        "priority": ["priority_name", "priorityName"],
        "summary": ["title"],
        "description": ["details", "body"],
        "keyword": ["query", "search_term", "searchTerm"],
    }
    for target, aliases in alias_map.items():
        if normalized.get(target):
            continue
        for alias in aliases:
            value = slots.get(alias)
            if value:
                normalized[target] = value
                break

    listable = ["project", "issue_type", "issue_key", "priority", "summary", "description", "keyword", "due_date"]
    for key in listable:
        value = normalized.get(key)
        if isinstance(value, list):
            normalized[key] = " ".join(str(item) for item in value)
    return normalized


def _faiss_topk(
    services: Services,
    query: str,
    candidates: Sequence[Issue],
    k: int = 5,
) -> List[Issue]:
    if not candidates:
        return []
    texts = [f"{issue.key} :: {issue.summary or ''}" for issue in candidates]
    vectors = services.embeddings.embed_documents(texts)
    if not vectors:
        return list(candidates)[:k]
    matrix = np.array(vectors, dtype="float32")
    faiss.normalize_L2(matrix)

    query_text = query or ""
    query_vec = np.array([services.embeddings.embed_query(query_text)], dtype="float32")
    faiss.normalize_L2(query_vec)

    index = faiss.IndexFlatIP(matrix.shape[1])
    index.add(matrix)
    top_k = min(k, len(candidates))
    scores, indices = index.search(query_vec, top_k)

    ranking: List[Tuple[Issue, float]] = []
    for score, idx in zip(scores[0], indices[0]):
        if idx == -1:
            continue
        ranking.append((candidates[idx], float(score)))

    ranking.sort(key=lambda item: item[1], reverse=True)
    return [issue for issue, _ in ranking]


def _format_issue_list(title: str, issues: Sequence[Issue]) -> str:
    lines = [title]
    for idx, issue in enumerate(issues, start=1):
        summary = (issue.summary or "(ìš”ì•½ ì—†ìŒ)").replace("\n", " ")
        status = issue.status or "None"
        priority = issue.priority or "None"
        due = issue.due_date or "None"
        lines.append(f"{idx}. {issue.key} Â· {summary} Â· ìƒíƒœ:{status} Â· ìš°ì„ :{priority} Â· ë§ˆê°:{due}")
    return "\n".join(lines)


def _format_issue_summary(issue: Issue) -> str:
    summary = (issue.summary or "(ìš”ì•½ ì—†ìŒ)").replace("\n", " ")
    status = issue.status or "None"
    priority = issue.priority or "None"
    due = issue.due_date or "None"
    assignee = issue.assignee or "None"
    lines = [
        f"- {issue.key} Â· {summary}",
        f"- ìƒíƒœ:{status} Â· ìš°ì„ :{priority} Â· ë§ˆê°:{due}",
        f"- ë‹´ë‹¹:{assignee}",
    ]
    return "\n".join(lines)


def _build_explain_prompt(issue: Issue, user_query: str) -> str:
    description = issue.description or "(ì„¤ëª… ì—†ìŒ)"
    template = textwrap.dedent(
        f"""
        ì‚¬ìš©ìž ìš”ì²­: {user_query}
        ì´ìŠˆ í‚¤: {issue.key}
        í”„ë¡œì íŠ¸: {issue.project}
        ì´ìŠˆ ìœ í˜•: {issue.issue_type}
        ìš”ì•½: {issue.summary}
        ìƒíƒœ: {issue.status}
        ìš°ì„ ìˆœìœ„: {issue.priority}
        ë§ˆê°ì¼: {issue.due_date}
        ë‹´ë‹¹ìž: {issue.assignee}
        ì„¤ëª…: {description}
        """
    ).strip()
    return template


def _reply(state: BotState, text: str, *, pending: Dict[str, Any]) -> Dict[str, Any]:
    messages = list(state.get("messages", []))
    messages.append(AIMessage(content=text))
    return {"messages": messages, "response": text, "pending": pending}


def run_cli() -> None:
    services = load_services()
    app = build_app(services)

    print("Jira CRUD ë´‡ (LangGraph + OpenAI) - CLI")
    print("ì¢…ë£Œ: Ctrl+C")

    history: List[BaseMessage] = []
    pending: Dict[str, Any] = {}

    while True:
        try:
            user_text = input("> ")
        except (EOFError, KeyboardInterrupt):
            print("\nì•ˆë…•ížˆ ê°€ì„¸ìš”!")
            break
        user_text = user_text.strip()
        if not user_text:
            continue

        human_msg = HumanMessage(content=user_text)
        state: BotState = {
            "messages": history + [human_msg],
            "user_input": user_text,
            "pending": pending,
        }
        result = app.invoke(state)
        response = result.get("response", "")
        if response:
            print(response)
        history = result.get("messages", history + [human_msg])
        pending = result.get("pending", {})


if __name__ == "__main__":
    run_cli()
